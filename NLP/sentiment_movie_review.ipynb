{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport sys\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom bs4 import BeautifulSoup      #for html removal       \nimport re                        #for number removal\nimport nltk                      #for stopwords removal\nimport nltk.data\nfrom gensim.models import Word2Vec\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer, WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"download from directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\nFileLinks('.') #lists all downloadable files on server","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/labeledTrainData.tsv',delimiter=\"\\t\", quoting=3,header=0)\ntest = pd.read_csv(\"../input/testData.tsv\", header=0, delimiter=\"\\t\",quoting=3 )\nunl_train=pd.read_csv(\"../input/unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\",quoting=3)\nprint(\"shape of train:\",train.shape)\nprint(\"shape of test:\",test.shape)\nprint(\"shape of unl_train:\",unl_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting all filters in a function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rev2words(rev):\n    #making beautyful/removing markups and tags\n    words=BeautifulSoup(rev).get_text()\n    #removing digits,symbols,and everything except plain letters\n    letters = re.sub(\"[^a-zA-Z0-9!?'-]\", \" \", words)\n    lemma=WordNetLemmatizer()\n    words_arr=[lemma.lemmatize(w) for w in word_tokenize(str(letters).lower())]\n    \n    stop_words=set(stopwords.words(\"english\"))\n    meaningful_words=[w for w in words_arr if w not in stop_words]\n    return \" \".join(meaningful_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['review'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rev2words(train['review'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_reviews = train[\"review\"].size\nclean_train_reviews = []\n\nprint (\"Cleaning and parsing the training set movie reviews...\\n\")\nclean_train_reviews = []\nfor i in range( 0, num_reviews ):\n    # If the index is evenly divisible by 1000, print a message,for progress\n    if( (i+1)%1000 == 0 ):\n        sys.stdout.write('\\r'+\"Review %d of %d\\t\" % (i+1, num_reviews))                                                                \n    clean_train_reviews.append( rev2words( train['review'][i] ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numOfRev=len(test)\nclean_test_reviews=[]\nprint(\"Cleaning and parsing the test set movie reviews...\\n\")\nfor i in range(0,numOfRev):\n    if( (i+1) % 1000 == 0 ):\n        sys.stdout.write('\\r'+\"Review %d of %d\\t\" % (i+1, numOfRev))\n    clean_review = rev2words( test[\"review\"][i] )\n    clean_test_reviews.append( clean_review )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"numOfRev=len(unl_train)\nclean_unl_reviews=[]\nprint(\"Cleaning and parsing the unlabled set movie reviews...\\n\")\nfor i in range(0,numOfRev):\n    if( (i+1) % 1000 == 0 ):\n        sys.stdout.write('\\r'+\"Review %d of %d\\t\" % (i+1, numOfRev))\n    clean_review = rev2words( test[\"review\"][i] )\n    clean_unl_reviews.append( clean_review )"},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating bag of words\n\nfrom sklearn.feature_extraction.text import CountVectorizer              #Importing Vectorizer\nvectorizer= CountVectorizer(analyzer='word',max_features=2500)\n\ntrain_data_features = vectorizer.fit_transform(clean_train_reviews)     #Vectorizing training Data\ntrain_data_features = train_data_features.toarray() \n\ntest_data_features = vectorizer.transform(clean_test_reviews)            #Vectorize Test Data\ntest_data_features = test_data_features.toarray()\nimport pickle\npickle.dump(vectorizer,open(\"vectorizer.pickle\",\"wb\"))\nprint(type(vectorizer))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer().fit(train_data_features)       #  TFIDF\nmessages_tfidf = tfidf_transformer.transform(train_data_features)\ntest_tfidf=tfidf_transformer.transform(test_data_features)\n\nfrom sklearn.svm import SVC, LinearSVC\nlinear_svc = LinearSVC()\nlinear_svc.fit(messages_tfidf, train['sentiment'])                  # SVM\npred = linear_svc.predict(test_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This is a singularity approach\nsample_rev='\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'\nclean_sample_rev=rev2words(sample_rev)\nsample_features=vectorizer.transform([clean_sample_rev])\nsample_features=sample_features.toarray()\n\nsample_tfidf=tfidf_transformer.transform(sample_features)\nlinear_svc.predict(sample_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n#pickle.dump(tfidf_transformer, open(\"tfidf_transformer.pickle\", \"wb\"))\n#pickle.dump(linear_svc,open(\"linear_svc.pickle\",\"wb\"))\npickle.dump(vectorizer,open(\"count_vec.pickle\",\"wb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_linear_svc = round(linear_svc.score(messages_tfidf, train['sentiment']) * 100, 2)\nacc_linear_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":pred} )\n\n# Use pandas to write the comma-separated output file\noutput.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}